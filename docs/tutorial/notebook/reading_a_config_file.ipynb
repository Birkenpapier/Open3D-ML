{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Controlling training and inference with config files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In other examples, we examine the following snippet of code which creates a dataset:\n",
    "\n",
    "```py\n",
    "# Read a dataset by specifying the path. We are also providing the cache directory and training split.\n",
    "\n",
    "dataset = ml3d.datasets.SemanticKITTI(dataset_path='SemanticKITTI/',\n",
    "                                      cache_dir='./logs/cache',\n",
    "                                      training_split=['00'],\n",
    "                                      validation_split=['01'],\n",
    "                                      test_split=['01'])\n",
    "```\n",
    "\n",
    "In the code above, the `dataset` object is created by explicitly passing dataset-specific parameters into `ml3d.datasets.SemanticKITTI()` method.\n",
    "\n",
    "Instead of passing a bunch of parameters to a function call as part of `dataset` object creation, we can supply `dataset` information from a specific *config* file. Each *config* file contains parameters for for a dataset, model and pipeline.\n",
    "\n",
    "\n",
    ">***Config* files pass information into Open3D-ML in YAML format.**\n",
    "\n",
    "\n",
    "In this example, we will:\n",
    "\n",
    "- Load a *config* `cfg_file` into a `Config` class object;\n",
    "- Parse `dataset` dictionaries from the `Config` object;\n",
    "- Access individual dictionaries in the `Config` object;\n",
    "- Access individual elements from within dictionaries.\n",
    "\n",
    "\n",
    "## Loading a *config* file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jupyter environment detected. Enabling Open3D WebVisualizer.\n",
      "[Open3D INFO] WebRTC GUI backend enabled.\n",
      "[Open3D INFO] WebRTCWindowSystem: HTTP handshake server disabled.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      " Using the Open3D PyTorch ops with CUDA 11 may have stability issues!\n",
      "\n",
      " We recommend to compile PyTorch from source with compile flags\n",
      "   '-Xcompiler -fno-gnu-unique'\n",
      "\n",
      " or use the PyTorch wheels at\n",
      "   https://github.com/isl-org/open3d_downloads/releases/tag/torch1.8.2\n",
      "\n",
      "\n",
      " Ignore this message if PyTorch has been compiled with the aforementioned\n",
      " flags.\n",
      "\n",
      " See https://github.com/isl-org/Open3D/issues/3324 and\n",
      " https://github.com/pytorch/pytorch/issues/52663 for more information on this\n",
      " problem.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-12 10:51:04.294784: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-04-12 10:51:04.294817: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    }
   ],
   "source": [
    "from open3d.ml import utils\n",
    "import open3d.ml.torch as ml3d"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we import two modules:\n",
    "    \n",
    "    1. `utils` - Open3D-ML utilities\n",
    "    2. `ml3d` - Open3D-ML Torch API library\n",
    "\n",
    "Now, we'll create *config*-specific objects:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg_file = \"../../../ml3d/configs/randlanet_semantickitti.yml\"\n",
    "cfg = utils.Config.load_from_file(cfg_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `cfg_file` holds the full path to the particular *config* file - `randlanet_semantickitti.yml`.\n",
    "The `cfg` object is initialized by the Open3D-ML `utils.Config.load_from_file()` method to hold parameters that are read from the `cfg_file`.\n",
    "\n",
    "## Examining dataset dictionaries in the `cfg` object\n",
    "\n",
    "Let's examine the contents of the `cfg` object:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'_cfg_dict': {'dataset': {'name': 'SemanticKITTI',\n",
       "   'dataset_path': None,\n",
       "   'cache_dir': './logs/cache',\n",
       "   'class_weights': [55437630,\n",
       "    320797,\n",
       "    541736,\n",
       "    2578735,\n",
       "    3274484,\n",
       "    552662,\n",
       "    184064,\n",
       "    78858,\n",
       "    240942562,\n",
       "    17294618,\n",
       "    170599734,\n",
       "    6369672,\n",
       "    230413074,\n",
       "    101130274,\n",
       "    476491114,\n",
       "    9833174,\n",
       "    129609852,\n",
       "    4506626,\n",
       "    1168181],\n",
       "   'test_result_folder': './test',\n",
       "   'test_split': ['11',\n",
       "    '12',\n",
       "    '13',\n",
       "    '14',\n",
       "    '15',\n",
       "    '16',\n",
       "    '17',\n",
       "    '18',\n",
       "    '19',\n",
       "    '20',\n",
       "    '21'],\n",
       "   'training_split': ['00',\n",
       "    '01',\n",
       "    '02',\n",
       "    '03',\n",
       "    '04',\n",
       "    '05',\n",
       "    '06',\n",
       "    '07',\n",
       "    '09',\n",
       "    '10'],\n",
       "   'all_split': ['00',\n",
       "    '01',\n",
       "    '02',\n",
       "    '03',\n",
       "    '04',\n",
       "    '05',\n",
       "    '06',\n",
       "    '07',\n",
       "    '09',\n",
       "    '08',\n",
       "    '10',\n",
       "    '11',\n",
       "    '12',\n",
       "    '13',\n",
       "    '14',\n",
       "    '15',\n",
       "    '16',\n",
       "    '17',\n",
       "    '18',\n",
       "    '19',\n",
       "    '20',\n",
       "    '21'],\n",
       "   'validation_split': ['08'],\n",
       "   'use_cache': True,\n",
       "   'sampler': {'name': 'SemSegRandomSampler'}},\n",
       "  'model': {'name': 'RandLANet',\n",
       "   'batcher': 'DefaultBatcher',\n",
       "   'ckpt_path': None,\n",
       "   'num_neighbors': 16,\n",
       "   'num_layers': 4,\n",
       "   'num_points': 45056,\n",
       "   'num_classes': 19,\n",
       "   'ignored_label_inds': [0],\n",
       "   'sub_sampling_ratio': [4, 4, 4, 4],\n",
       "   'in_channels': 3,\n",
       "   'dim_features': 8,\n",
       "   'dim_output': [16, 64, 128, 256],\n",
       "   'grid_size': 0.06,\n",
       "   'augment': {'recenter': {'dim': [0, 1]}}},\n",
       "  'pipeline': {'name': 'SemanticSegmentation',\n",
       "   'optimizer': {'lr': 0.001},\n",
       "   'batch_size': 4,\n",
       "   'main_log_dir': './logs',\n",
       "   'max_epoch': 100,\n",
       "   'save_ckpt_freq': 5,\n",
       "   'scheduler_gamma': 0.9886,\n",
       "   'test_batch_size': 1,\n",
       "   'train_sum_dir': 'train_log',\n",
       "   'val_batch_size': 2,\n",
       "   'summary': {'record_for': [],\n",
       "    'max_pts': None,\n",
       "    'use_reference': False,\n",
       "    'max_outputs': 1}}},\n",
       " 'cfg_dict': {'dataset': {'name': 'SemanticKITTI',\n",
       "   'dataset_path': None,\n",
       "   'cache_dir': './logs/cache',\n",
       "   'class_weights': [55437630,\n",
       "    320797,\n",
       "    541736,\n",
       "    2578735,\n",
       "    3274484,\n",
       "    552662,\n",
       "    184064,\n",
       "    78858,\n",
       "    240942562,\n",
       "    17294618,\n",
       "    170599734,\n",
       "    6369672,\n",
       "    230413074,\n",
       "    101130274,\n",
       "    476491114,\n",
       "    9833174,\n",
       "    129609852,\n",
       "    4506626,\n",
       "    1168181],\n",
       "   'test_result_folder': './test',\n",
       "   'test_split': ['11',\n",
       "    '12',\n",
       "    '13',\n",
       "    '14',\n",
       "    '15',\n",
       "    '16',\n",
       "    '17',\n",
       "    '18',\n",
       "    '19',\n",
       "    '20',\n",
       "    '21'],\n",
       "   'training_split': ['00',\n",
       "    '01',\n",
       "    '02',\n",
       "    '03',\n",
       "    '04',\n",
       "    '05',\n",
       "    '06',\n",
       "    '07',\n",
       "    '09',\n",
       "    '10'],\n",
       "   'all_split': ['00',\n",
       "    '01',\n",
       "    '02',\n",
       "    '03',\n",
       "    '04',\n",
       "    '05',\n",
       "    '06',\n",
       "    '07',\n",
       "    '09',\n",
       "    '08',\n",
       "    '10',\n",
       "    '11',\n",
       "    '12',\n",
       "    '13',\n",
       "    '14',\n",
       "    '15',\n",
       "    '16',\n",
       "    '17',\n",
       "    '18',\n",
       "    '19',\n",
       "    '20',\n",
       "    '21'],\n",
       "   'validation_split': ['08'],\n",
       "   'use_cache': True,\n",
       "   'sampler': {'name': 'SemSegRandomSampler'}},\n",
       "  'model': {'name': 'RandLANet',\n",
       "   'batcher': 'DefaultBatcher',\n",
       "   'ckpt_path': None,\n",
       "   'num_neighbors': 16,\n",
       "   'num_layers': 4,\n",
       "   'num_points': 45056,\n",
       "   'num_classes': 19,\n",
       "   'ignored_label_inds': [0],\n",
       "   'sub_sampling_ratio': [4, 4, 4, 4],\n",
       "   'in_channels': 3,\n",
       "   'dim_features': 8,\n",
       "   'dim_output': [16, 64, 128, 256],\n",
       "   'grid_size': 0.06,\n",
       "   'augment': {'recenter': {'dim': [0, 1]}}},\n",
       "  'pipeline': {'name': 'SemanticSegmentation',\n",
       "   'optimizer': {'lr': 0.001},\n",
       "   'batch_size': 4,\n",
       "   'main_log_dir': './logs',\n",
       "   'max_epoch': 100,\n",
       "   'save_ckpt_freq': 5,\n",
       "   'scheduler_gamma': 0.9886,\n",
       "   'test_batch_size': 1,\n",
       "   'train_sum_dir': 'train_log',\n",
       "   'val_batch_size': 2,\n",
       "   'summary': {'record_for': [],\n",
       "    'max_pts': None,\n",
       "    'use_reference': False,\n",
       "    'max_outputs': 1}}}}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vars(cfg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`vars(cfg)` returns the three dictionaries: `dataset`, `model`, and `pipeline`.\n",
    "\n",
    "Now, let's explore them. The first one to look at is the `cfg.dataset`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg.dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Accessing individual dictionary items\n",
    "\n",
    "These `cfg` dictionary items can be viewed as well as updated like in a standard Python dictionary. We can access individual items of the `cfg.dataset` dictionary like so: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg.dataset['name']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `cfg.model` and `cfg.pipeline` dictionaries\n",
    "\n",
    "We'll later revisit the `cfg.dataset`. Next, let's look at the `cfg.model` dictionary:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cfg.model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Just as in the case of `cfg.dataset`, we can access `cfg.model` dictionary items by referencing them individually:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg.model['sub_sampling_ratio']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`cfg.pipeline` is the last dictionary item of the `cfg` object:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg.pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Likewise, individual dictionary items in `cfg.pipeline` can be accesed just like those of `cfg.model` and `cfg.dataset`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg.pipeline['name']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initializing datasets from *config* files\n",
    "\n",
    "Next, we explicitly create the `dataset` object which will hold all information from the `cfg.dataset` dictionary:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = ml3d.datasets.SemanticKITTI(cfg.dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we'll look at what properties the newly-created `dataset` object exposes with the Python `vars()` function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vars(dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can reference any property of the dataset by using *`object.property`* syntax. For example, to find out what value the `num_classes` property holds, we type in:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.num_classes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Likewise, to extract information from a `label_to_names` property which maps labels to the objects names, we call:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.label_to_names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Experiment with other `dataset` properties to see how convenient it is to reference them."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
